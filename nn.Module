Transforms:变换图像使其满足神经网络的输入要求

Build Model:
get device for training
所有网络模型都是继承自nn.Module
__init__(self)
	实例化父类，nn.Flatten，nn.Sequential，nn.Linear(输入特征维度，隐含层大小)，
forward(self,x)

实例化自定义模型：
model=network().to(device)#将模型调到设备上
开源项目：summary：可以查看模型参数，形状，层名称

使用模型：
logits=model(tensor)
pred_probab=nn.Softmax(dim=1)(logits)

flatten=nn.Flatten
torch.nn.Flatten(start_dim=1,end_dim=-1)#浓缩维度

nn.Linear(in_features,out_features,bias,device,dtype)：全连接层（线性层）

nn.ReLU#类需要实例化，不能直接调用

nn.Sequential：容器化，将所有层组合成一个顺序容器，形成完整的神经网络模型

nn.Dropout: 添加dropout层

nn.Softmax

named_parameters:返回元组

nn.Module源码（所有模块的基类）

add_module(name,module)

buffers(recurse=True)

eval()#模式

get_parameter

load_state_dict(state_dict,strict=True)#加载模型参数与buffer

requires_grad_(requires_grad=True)#是否需要梯度运算

torch.save({'epoch': ,
'model_state_dict',
'optimizer_state_dict',
'loss',
},PATH)

model.load_state_dict
optimizer.load_state_dict

nn.module:
__init__:
	self.training
	self._parameters

register_buffer:
	#buffer:不是参数，是模型的状态，可以保存也可以不保存
	
register_parameter(name,param):#添加参数到模型

get_buffer

_apply(self,fn):
#调用所有子模块、参数并遍历，应用到自身；用于模型参数初始化
 
cuda():#调到gpu
_apply(lambda t: t.cuda(device))

type():#转换类型

to_empty:
#所有参数与buffer移动到设备上，但是不带值
