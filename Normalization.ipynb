{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Normalization论文讲解：\n",
    "归一化可以减少神经网络训练时间\n",
    "批归一化：\n",
    "求小批次训练样本的分布，再求均值和方差，再对输入归一化。可以减低fnn训练时间。依赖于mini-batch的大小，不知道如何应用于RNN。\n",
    "层归一化：\n",
    "对单个样本归一化。训练和测试表现一样。可用于RNN，对每一个时间点进行归一化\n",
    "\n",
    "深度学习网络：非线性映射\n",
    "\n",
    "批归一化：\n",
    "对小批次样本内部所有维度内做同样的归一化，以此来估计全部样本的均值和方差，因此batch_size越小误差越大\n",
    "\n",
    "层归一化：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Normalization：批归一化（NLP很少用）\n",
    "per channel across mini-batch\n",
    "class(类，需要实例化)： torch.nn.BatchNorm1d(num_features，eps=1e-5,momentum，affine,track_running_stats,device,dtype)\n",
    "num_features:输入的通道数\n",
    "eps：分母数值稳定\n",
    "momentum：动量\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "batch_size=2\n",
    "time_steps=3\n",
    "embedding_dim=4\n",
    "inputx=torch.randn(batch_size,time_steps,embedding_dim)# N* L *C\n",
    "batch_norm_op=torch.nn.BatchNorm1d(embedding_dim,affine=False)\n",
    "bn_y=batch_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)#两次转置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bn_mean=inputx.mean(dim=(0,1),keepdim=True)\n",
    "bn_std=inputx.std(dim=(0,1),unbiased=False,keepdim=True)\n",
    "verify_bn_y=(inputx-bn_mean)/(bn_std+1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Normalization:层归一化（NLP常用）\n",
    "per sample,per layer\n",
    "torch.nn.LayerNorm(normalized_shape,eps=1e-5,elementwise_affine=True,device=None,dtype=None)\n",
    "\n",
    "api实例化：\n",
    "layer_norm_op=torch.nn.LayerNorm(embedding_dim,elementwise_affine=False)\n",
    "ln_y=layer_norm_op(inputx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ln_mean=inputx.mean(dim=-1,keepdim=True)\n",
    "ln_std=inputx.mean(dim=-1,keepdim=True,unbiased=False)\n",
    "verify_ln_y=(inputx-ln_mean)/(ln_std+1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance Normalization:实例归一化(用于风格迁移)\n",
    "per sample,per channel\n",
    "\n",
    "torch.nn.InstanceNorm1d(num_features,eps=1e-5,momentum=0.1,affine=Fasle,track_running_stats=False)\n",
    "\n",
    "api实例化：\n",
    "ins_norm_op=torch.nn.InstanceNorm1d(embedding_dim)\n",
    "in_y=ins_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "in_mean=inputx.mean(dim=1,keepdim=True)\n",
    "in_std=inputx.std(dim=1,keepdim=True,unbiased=False)\n",
    "verify_in_y=(inputx-in_mean)/(in_std+1e-5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
