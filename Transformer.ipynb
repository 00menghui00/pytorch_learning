{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN:\n",
    "权重共享（平移不变性，可并行计算），滑动窗口（局部关联性-依靠多层堆积进行长程建模），对相对位置敏感、对绝对位置不敏感\n",
    "\n",
    "RNN:\n",
    "依次有序递归建模。\n",
    "对顺序敏感，串行计算耗时，长程建模能力弱，计算复杂度与序列长度呈线性关系，单步复杂度不变，对相对位置敏感、对绝对位置敏感\n",
    "\n",
    "transformer：\n",
    "无局部假设：可并行计算，对相对位置不敏感\n",
    "无有序假设：需要位置编码来反映位置变化对特征的影响，对绝对位置不敏感\n",
    "任意两字符都可建模：擅长长程建模，自注意力机制需要序列长度的平方级别的复杂度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformer:\n",
    "encode-decode\n",
    "# encoder:\n",
    "## input word embedding\n",
    "由稀疏的one-hot进入一个不带bias的FFN（全连接网络）得到一个稠密的连续向量，用稠密的连续向量表示一个单词\n",
    "## position encoding\n",
    "通过sin/cos固定表征：每个位置都确定，对于不同的句子相同位置的距离都一致，可以推广到更长的测试句子。\n",
    "pe（pos+k）可以写成pe（pos）的线性组合：测试集中未见过的句子可以用训练集推广。\n",
    "通过残差连接使位置信息流入深层。\n",
    "## multi-head self-attention：\n",
    "使建模能力更强，表征空间更丰富：多头可以捕捉更多位置与位置的关系。\n",
    "由多组Q，K，V构成，每组单独计算一个attention向量。\n",
    "把每组的attention向量拼接，并进入一个FFN得到最终的向量。\n",
    "## feed-forward network\n",
    "只考虑每个单独位置进行建模：只考虑每一个位置上的字符。\n",
    "不同位置参数共享。\n",
    "类似于1*1 pointwise convolution:只考虑每一个单独的像素点。\n",
    "\n",
    "# decoder\n",
    "## output word embedding\n",
    "## masked multi-head self-attention\n",
    "## multi-head cross-attention\n",
    "## feed-forward network\n",
    "## softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#pytorch API\n",
    "\n",
    "class Transformer(Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            d_model(特征维度)，\n",
    "            nhead(头数目)，\n",
    "            num_encoder_layers，\n",
    "            num_decoder_layers,\n",
    "            dim_feedforward(全连接层的中间特征维度)，\n",
    "            dropout，\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
