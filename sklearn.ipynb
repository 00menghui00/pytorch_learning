{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn.metrics 包含了一系列常用于评估机器学习模型性能的工具和指标\n",
    "\n",
    "## \n",
    "confusion_matrix 函数用于计算分类问题中的混淆矩阵。混淆矩阵是一个表格，用于描述分类模型在不同类别上的表现，显示了真实标签与预测标签之间的关系。\n",
    "\n",
    "混淆矩阵结构：\n",
    "True Positive (TP)：真实为正类，预测也为正类。\n",
    "True Negative (TN)：真实为负类，预测也为负类。\n",
    "False Positive (FP)：真实为负类，预测为正类。\n",
    "False Negative (FN)：真实为正类，预测为负类。\n",
    "通过这些值，可以计算出各种评估指标，如准确率、精确度、召回率等\n",
    "\n",
    "##\n",
    "classification_report 函数提供了包括准确率、精确度、召回率和 F1 分数等在内的多种常用评估指标的详细报告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing 模块 包含用于数据预处理的函数和类，例如标准化、归一化、特征缩放等。\n",
    "\n",
    "MinMaxScaler 类 用于将数据缩放到一个指定的范围，通常是 0 到 1 之间。这个过程也称为归一化或最小-最大缩放。\n",
    "\n",
    "具体来说，MinMaxScaler 的作用是：\n",
    "\n",
    "对于数据集中的每个特征（列），MinMaxScaler 会将其值缩放到指定的范围内。默认情况下，这个范围是 0 到 1。缩放的公式如下：\n",
    "\n",
    "X_scaled = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "其中：\n",
    "\n",
    "X 是原始数据值。\n",
    "X_min 是该特征在原始数据中的最小值。\n",
    "X_max 是该特征在原始数据中的最大值。\n",
    "X_scaled 是缩放后的数据值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection 模块 包含用于模型选择和评估的工具，例如交叉验证、数据集划分、超参数搜索等。\n",
    "\n",
    "train_test_split 函数 用于将数据集划分为训练集和测试集（或训练集、验证集和测试集）\n",
    "\n",
    "sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
    "\n",
    "2.0 Flash Experimental. Might not work as expected.\n",
    "train_test_split 函数是 scikit-learn (sklearn) 库中一个常用的工具，用于将数据集划分为训练集和测试集。这是机器学习中一个非常重要的步骤，用于评估模型的泛化能力，即模型在未见过的数据上的表现。\n",
    "\n",
    "函数签名：\n",
    "\n",
    "Python\n",
    "\n",
    "sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
    "主要参数解释：\n",
    "\n",
    "*arrays: 可变长度参数，可以传入多个数组或矩阵（例如 NumPy 数组、pandas DataFrame）。这些数组或矩阵的第一个维度（行数）必须相同。通常传入特征矩阵 X 和目标向量 y。\n",
    "test_size: 测试集的大小。可以是一个浮点数（0.0 到 1.0 之间），表示测试集占总数据集的比例；也可以是一个整数，表示测试集的样本数量。如果 train_size 未指定，则 test_size 默认为 0.25。\n",
    "train_size: 训练集的大小。可以是一个浮点数（0.0 到 1.0 之间），表示训练集占总数据集的比例；也可以是一个整数，表示训练集的样本数量。如果 test_size 未指定，则 train_size 默认为 1 - test_size。如果 test_size 和 train_size 都未指定，则 test_size 默认为 0.25。\n",
    "random_state: 随机数种子。用于控制数据集划分的随机性。如果设置了相同的 random_state 值，则每次划分的结果都相同。这对于复现实验结果非常重要。\n",
    "shuffle: 是否在划分数据之前进行洗牌。默认为 True。通常需要洗牌以确保训练集和测试集中的数据分布相似。\n",
    "stratify: 分层抽样。如果指定了 stratify=y，则按照目标变量 y 的分布进行分层抽样，确保训练集和测试集中各类别的比例与原始数据集中各类别的比例相同。这在处理不平衡数据集时非常有用。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
